digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label="X[43] <= 2.03\nentropy = 0.94\nsamples = 2855\nvalue = [1944, 897, 14]\nclass = Winner", fillcolor="#e5813988"] ;
1 [label="X[38] <= 162.5\nentropy = 0.835\nsamples = 1195\nvalue = [908, 280, 7]\nclass = Winner", fillcolor="#e58139af"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label="X[47] <= 0.099\nentropy = 0.971\nsamples = 475\nvalue = [323, 147, 5]\nclass = Winner", fillcolor="#e5813989"] ;
1 -> 2 ;
3 [label="X[55] <= 63.5\nentropy = 0.934\nsamples = 269\nvalue = [175, 94, 0]\nclass = Winner", fillcolor="#e5813976"] ;
2 -> 3 ;
4 [label="entropy = 0.0\nsamples = 15\nvalue = [15, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
3 -> 4 ;
5 [label="entropy = 0.951\nsamples = 254\nvalue = [160, 94, 0]\nclass = Winner", fillcolor="#e5813969"] ;
3 -> 5 ;
6 [label="X[44] <= 0.744\nentropy = 0.977\nsamples = 206\nvalue = [148, 53, 5]\nclass = Winner", fillcolor="#e581399e"] ;
2 -> 6 ;
7 [label="entropy = 1.029\nsamples = 130\nvalue = [84, 44, 2]\nclass = Winner", fillcolor="#e5813977"] ;
6 -> 7 ;
8 [label="entropy = 0.757\nsamples = 76\nvalue = [64, 9, 3]\nclass = Winner", fillcolor="#e58139d1"] ;
6 -> 8 ;
9 [label="X[51] <= 7.5\nentropy = 0.717\nsamples = 720\nvalue = [585, 133, 2]\nclass = Winner", fillcolor="#e58139c4"] ;
1 -> 9 ;
10 [label="X[46] <= 2.36\nentropy = 0.769\nsamples = 609\nvalue = [480, 127, 2]\nclass = Winner", fillcolor="#e58139bb"] ;
9 -> 10 ;
11 [label="entropy = 0.72\nsamples = 526\nvalue = [428, 96, 2]\nclass = Winner", fillcolor="#e58139c5"] ;
10 -> 11 ;
12 [label="entropy = 0.953\nsamples = 83\nvalue = [52, 31, 0]\nclass = Winner", fillcolor="#e5813967"] ;
10 -> 12 ;
13 [label="X[62] <= 1.957\nentropy = 0.303\nsamples = 111\nvalue = [105, 6, 0]\nclass = Winner", fillcolor="#e58139f0"] ;
9 -> 13 ;
14 [label="entropy = 0.0\nsamples = 61\nvalue = [61, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
13 -> 14 ;
15 [label="entropy = 0.529\nsamples = 50\nvalue = [44, 6, 0]\nclass = Winner", fillcolor="#e58139dc"] ;
13 -> 15 ;
16 [label="X[43] <= 3.944\nentropy = 0.988\nsamples = 1660\nvalue = [1036, 617, 7]\nclass = Winner", fillcolor="#e5813966"] ;
0 -> 16 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
17 [label="X[51] <= 2.5\nentropy = 0.977\nsamples = 1348\nvalue = [870, 471, 7]\nclass = Winner", fillcolor="#e5813974"] ;
16 -> 17 ;
18 [label="X[47] <= 0.163\nentropy = 1.044\nsamples = 512\nvalue = [290, 218, 4]\nclass = Winner", fillcolor="#e581393e"] ;
17 -> 18 ;
19 [label="entropy = 1.035\nsamples = 219\nvalue = [102, 116, 1]\nclass = Loser", fillcolor="#39e5811f"] ;
18 -> 19 ;
20 [label="entropy = 1.008\nsamples = 293\nvalue = [188, 102, 3]\nclass = Winner", fillcolor="#e5813973"] ;
18 -> 20 ;
21 [label="X[57] <= 2.734\nentropy = 0.917\nsamples = 836\nvalue = [580, 253, 3]\nclass = Winner", fillcolor="#e581398f"] ;
17 -> 21 ;
22 [label="entropy = 0.864\nsamples = 414\nvalue = [309, 102, 3]\nclass = Winner", fillcolor="#e58139a9"] ;
21 -> 22 ;
23 [label="entropy = 0.941\nsamples = 422\nvalue = [271, 151, 0]\nclass = Winner", fillcolor="#e5813971"] ;
21 -> 23 ;
24 [label="X[38] <= 150.0\nentropy = 0.997\nsamples = 312\nvalue = [166, 146, 0]\nclass = Winner", fillcolor="#e581391f"] ;
16 -> 24 ;
25 [label="X[60] <= 0.687\nentropy = 0.965\nsamples = 100\nvalue = [39, 61, 0]\nclass = Loser", fillcolor="#39e5815c"] ;
24 -> 25 ;
26 [label="entropy = 0.99\nsamples = 50\nvalue = [28, 22, 0]\nclass = Winner", fillcolor="#e5813937"] ;
25 -> 26 ;
27 [label="entropy = 0.76\nsamples = 50\nvalue = [11, 39, 0]\nclass = Loser", fillcolor="#39e581b7"] ;
25 -> 27 ;
28 [label="X[61] <= 0.013\nentropy = 0.971\nsamples = 212\nvalue = [127, 85, 0]\nclass = Winner", fillcolor="#e5813954"] ;
24 -> 28 ;
29 [label="entropy = 0.934\nsamples = 177\nvalue = [115, 62, 0]\nclass = Winner", fillcolor="#e5813976"] ;
28 -> 29 ;
30 [label="entropy = 0.928\nsamples = 35\nvalue = [12, 23, 0]\nclass = Loser", fillcolor="#39e5817a"] ;
28 -> 30 ;
}

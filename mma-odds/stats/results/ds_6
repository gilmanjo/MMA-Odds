digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label="X[43] <= 2.03\nentropy = 0.94\nsamples = 2855\nvalue = [1944, 897, 14]\nclass = Winner", fillcolor="#e5813988"] ;
1 [label="X[38] <= 162.5\nentropy = 0.835\nsamples = 1195\nvalue = [908, 280, 7]\nclass = Winner", fillcolor="#e58139af"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label="X[47] <= 0.099\nentropy = 0.971\nsamples = 475\nvalue = [323, 147, 5]\nclass = Winner", fillcolor="#e5813989"] ;
1 -> 2 ;
3 [label="X[55] <= 63.5\nentropy = 0.934\nsamples = 269\nvalue = [175, 94, 0]\nclass = Winner", fillcolor="#e5813976"] ;
2 -> 3 ;
4 [label="entropy = 0.0\nsamples = 15\nvalue = [15, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
3 -> 4 ;
5 [label="X[59] <= 4.258\nentropy = 0.951\nsamples = 254\nvalue = [160, 94, 0]\nclass = Winner", fillcolor="#e5813969"] ;
3 -> 5 ;
6 [label="X[50] <= 22.5\nentropy = 0.963\nsamples = 243\nvalue = [149, 94, 0]\nclass = Winner", fillcolor="#e581395e"] ;
5 -> 6 ;
7 [label="entropy = 0.983\nsamples = 210\nvalue = [121, 89, 0]\nclass = Winner", fillcolor="#e5813943"] ;
6 -> 7 ;
8 [label="entropy = 0.614\nsamples = 33\nvalue = [28, 5, 0]\nclass = Winner", fillcolor="#e58139d1"] ;
6 -> 8 ;
9 [label="entropy = 0.0\nsamples = 11\nvalue = [11, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
5 -> 9 ;
10 [label="X[44] <= 0.744\nentropy = 0.977\nsamples = 206\nvalue = [148, 53, 5]\nclass = Winner", fillcolor="#e581399e"] ;
2 -> 10 ;
11 [label="X[10] <= 0.5\nentropy = 1.029\nsamples = 130\nvalue = [84, 44, 2]\nclass = Winner", fillcolor="#e5813977"] ;
10 -> 11 ;
12 [label="X[51] <= 4.5\nentropy = 0.959\nsamples = 103\nvalue = [74, 27, 2]\nclass = Winner", fillcolor="#e581399e"] ;
11 -> 12 ;
13 [label="entropy = 1.091\nsamples = 71\nvalue = [45, 24, 2]\nclass = Winner", fillcolor="#e5813972"] ;
12 -> 13 ;
14 [label="entropy = 0.449\nsamples = 32\nvalue = [29, 3, 0]\nclass = Winner", fillcolor="#e58139e5"] ;
12 -> 14 ;
15 [label="X[61] <= 0.009\nentropy = 0.951\nsamples = 27\nvalue = [10, 17, 0]\nclass = Loser", fillcolor="#39e58169"] ;
11 -> 15 ;
16 [label="entropy = 0.722\nsamples = 20\nvalue = [4, 16, 0]\nclass = Loser", fillcolor="#39e581bf"] ;
15 -> 16 ;
17 [label="entropy = 0.592\nsamples = 7\nvalue = [6, 1, 0]\nclass = Winner", fillcolor="#e58139d4"] ;
15 -> 17 ;
18 [label="X[59] <= 1.514\nentropy = 0.757\nsamples = 76\nvalue = [64, 9, 3]\nclass = Winner", fillcolor="#e58139d1"] ;
10 -> 18 ;
19 [label="X[59] <= 1.265\nentropy = 1.173\nsamples = 27\nvalue = [18, 7, 2]\nclass = Winner", fillcolor="#e581398c"] ;
18 -> 19 ;
20 [label="entropy = 0.832\nsamples = 22\nvalue = [18, 3, 1]\nclass = Winner", fillcolor="#e58139c9"] ;
19 -> 20 ;
21 [label="entropy = 0.722\nsamples = 5\nvalue = [0, 4, 1]\nclass = Loser", fillcolor="#39e581bf"] ;
19 -> 21 ;
22 [label="X[47] <= 0.107\nentropy = 0.389\nsamples = 49\nvalue = [46, 2, 1]\nclass = Winner", fillcolor="#e58139ef"] ;
18 -> 22 ;
23 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]\nclass = N/A", fillcolor="#8139e5ff"] ;
22 -> 23 ;
24 [label="entropy = 0.25\nsamples = 48\nvalue = [46, 2, 0]\nclass = Winner", fillcolor="#e58139f4"] ;
22 -> 24 ;
25 [label="X[51] <= 7.5\nentropy = 0.717\nsamples = 720\nvalue = [585, 133, 2]\nclass = Winner", fillcolor="#e58139c4"] ;
1 -> 25 ;
26 [label="X[46] <= 2.36\nentropy = 0.769\nsamples = 609\nvalue = [480, 127, 2]\nclass = Winner", fillcolor="#e58139bb"] ;
25 -> 26 ;
27 [label="X[58] <= 0.641\nentropy = 0.72\nsamples = 526\nvalue = [428, 96, 2]\nclass = Winner", fillcolor="#e58139c5"] ;
26 -> 27 ;
28 [label="X[39] <= 81.5\nentropy = 0.747\nsamples = 494\nvalue = [396, 96, 2]\nclass = Winner", fillcolor="#e58139c0"] ;
27 -> 28 ;
29 [label="entropy = 0.744\nsamples = 479\nvalue = [382, 96, 1]\nclass = Winner", fillcolor="#e58139be"] ;
28 -> 29 ;
30 [label="entropy = 0.353\nsamples = 15\nvalue = [14, 0, 1]\nclass = Winner", fillcolor="#e58139ed"] ;
28 -> 30 ;
31 [label="entropy = 0.0\nsamples = 32\nvalue = [32, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
27 -> 31 ;
32 [label="X[50] <= 8.5\nentropy = 0.953\nsamples = 83\nvalue = [52, 31, 0]\nclass = Winner", fillcolor="#e5813967"] ;
26 -> 32 ;
33 [label="X[58] <= 0.518\nentropy = 0.684\nsamples = 11\nvalue = [2, 9, 0]\nclass = Loser", fillcolor="#39e581c6"] ;
32 -> 33 ;
34 [label="entropy = 0.0\nsamples = 8\nvalue = [0, 8, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
33 -> 34 ;
35 [label="entropy = 0.918\nsamples = 3\nvalue = [2, 1, 0]\nclass = Winner", fillcolor="#e581397f"] ;
33 -> 35 ;
36 [label="X[44] <= 0.689\nentropy = 0.888\nsamples = 72\nvalue = [50, 22, 0]\nclass = Winner", fillcolor="#e581398f"] ;
32 -> 36 ;
37 [label="entropy = 0.297\nsamples = 19\nvalue = [18, 1, 0]\nclass = Winner", fillcolor="#e58139f1"] ;
36 -> 37 ;
38 [label="entropy = 0.969\nsamples = 53\nvalue = [32, 21, 0]\nclass = Winner", fillcolor="#e5813958"] ;
36 -> 38 ;
39 [label="X[62] <= 1.957\nentropy = 0.303\nsamples = 111\nvalue = [105, 6, 0]\nclass = Winner", fillcolor="#e58139f0"] ;
25 -> 39 ;
40 [label="entropy = 0.0\nsamples = 61\nvalue = [61, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
39 -> 40 ;
41 [label="X[47] <= 0.455\nentropy = 0.529\nsamples = 50\nvalue = [44, 6, 0]\nclass = Winner", fillcolor="#e58139dc"] ;
39 -> 41 ;
42 [label="X[39] <= 69.5\nentropy = 0.179\nsamples = 37\nvalue = [36, 1, 0]\nclass = Winner", fillcolor="#e58139f8"] ;
41 -> 42 ;
43 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
42 -> 43 ;
44 [label="entropy = 0.0\nsamples = 36\nvalue = [36, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
42 -> 44 ;
45 [label="X[48] <= 0.007\nentropy = 0.961\nsamples = 13\nvalue = [8, 5, 0]\nclass = Winner", fillcolor="#e5813960"] ;
41 -> 45 ;
46 [label="entropy = 0.954\nsamples = 8\nvalue = [3, 5, 0]\nclass = Loser", fillcolor="#39e58166"] ;
45 -> 46 ;
47 [label="entropy = 0.0\nsamples = 5\nvalue = [5, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
45 -> 47 ;
48 [label="X[43] <= 3.944\nentropy = 0.988\nsamples = 1660\nvalue = [1036, 617, 7]\nclass = Winner", fillcolor="#e5813966"] ;
0 -> 48 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
49 [label="X[51] <= 2.5\nentropy = 0.977\nsamples = 1348\nvalue = [870, 471, 7]\nclass = Winner", fillcolor="#e5813974"] ;
48 -> 49 ;
50 [label="X[47] <= 0.163\nentropy = 1.044\nsamples = 512\nvalue = [290, 218, 4]\nclass = Winner", fillcolor="#e581393e"] ;
49 -> 50 ;
51 [label="X[60] <= 0.675\nentropy = 1.035\nsamples = 219\nvalue = [102, 116, 1]\nclass = Loser", fillcolor="#39e5811f"] ;
50 -> 51 ;
52 [label="X[43] <= 2.972\nentropy = 0.951\nsamples = 81\nvalue = [51, 30, 0]\nclass = Winner", fillcolor="#e5813969"] ;
51 -> 52 ;
53 [label="entropy = 0.803\nsamples = 49\nvalue = [37, 12, 0]\nclass = Winner", fillcolor="#e58139ac"] ;
52 -> 53 ;
54 [label="entropy = 0.989\nsamples = 32\nvalue = [14, 18, 0]\nclass = Loser", fillcolor="#39e58139"] ;
52 -> 54 ;
55 [label="X[53] <= 74.5\nentropy = 1.007\nsamples = 138\nvalue = [51, 86, 1]\nclass = Loser", fillcolor="#39e58167"] ;
51 -> 55 ;
56 [label="entropy = 0.971\nsamples = 121\nvalue = [39, 81, 1]\nclass = Loser", fillcolor="#39e58183"] ;
55 -> 56 ;
57 [label="entropy = 0.874\nsamples = 17\nvalue = [12, 5, 0]\nclass = Winner", fillcolor="#e5813995"] ;
55 -> 57 ;
58 [label="X[63] <= 0.629\nentropy = 1.008\nsamples = 293\nvalue = [188, 102, 3]\nclass = Winner", fillcolor="#e5813973"] ;
50 -> 58 ;
59 [label="X[46] <= 1.971\nentropy = 0.95\nsamples = 241\nvalue = [166, 73, 2]\nclass = Winner", fillcolor="#e581398d"] ;
58 -> 59 ;
60 [label="entropy = 0.757\nsamples = 119\nvalue = [93, 26, 0]\nclass = Winner", fillcolor="#e58139b8"] ;
59 -> 60 ;
61 [label="entropy = 1.071\nsamples = 122\nvalue = [73, 47, 2]\nclass = Winner", fillcolor="#e5813958"] ;
59 -> 61 ;
62 [label="X[55] <= 72.5\nentropy = 1.104\nsamples = 52\nvalue = [22, 29, 1]\nclass = Loser", fillcolor="#39e5813c"] ;
58 -> 62 ;
63 [label="entropy = 0.906\nsamples = 28\nvalue = [19, 9, 0]\nclass = Winner", fillcolor="#e5813986"] ;
62 -> 63 ;
64 [label="entropy = 0.785\nsamples = 24\nvalue = [3, 20, 1]\nclass = Loser", fillcolor="#39e581ce"] ;
62 -> 64 ;
65 [label="X[57] <= 2.734\nentropy = 0.917\nsamples = 836\nvalue = [580, 253, 3]\nclass = Winner", fillcolor="#e581398f"] ;
49 -> 65 ;
66 [label="X[36] <= 0.5\nentropy = 0.864\nsamples = 414\nvalue = [309, 102, 3]\nclass = Winner", fillcolor="#e58139a9"] ;
65 -> 66 ;
67 [label="X[34] <= 30.0\nentropy = 0.763\nsamples = 325\nvalue = [257, 67, 1]\nclass = Winner", fillcolor="#e58139bc"] ;
66 -> 67 ;
68 [label="entropy = 0.731\nsamples = 316\nvalue = [255, 60, 1]\nclass = Winner", fillcolor="#e58139c2"] ;
67 -> 68 ;
69 [label="entropy = 0.764\nsamples = 9\nvalue = [2, 7, 0]\nclass = Loser", fillcolor="#39e581b6"] ;
67 -> 69 ;
70 [label="X[43] <= 2.192\nentropy = 1.106\nsamples = 89\nvalue = [52, 35, 2]\nclass = Winner", fillcolor="#e5813950"] ;
66 -> 70 ;
71 [label="entropy = 1.42\nsamples = 13\nvalue = [4, 7, 2]\nclass = Loser", fillcolor="#39e58155"] ;
70 -> 71 ;
72 [label="entropy = 0.949\nsamples = 76\nvalue = [48, 28, 0]\nclass = Winner", fillcolor="#e581396a"] ;
70 -> 72 ;
73 [label="X[47] <= 0.38\nentropy = 0.941\nsamples = 422\nvalue = [271, 151, 0]\nclass = Winner", fillcolor="#e5813971"] ;
65 -> 73 ;
74 [label="X[47] <= 0.371\nentropy = 0.973\nsamples = 312\nvalue = [186, 126, 0]\nclass = Winner", fillcolor="#e5813952"] ;
73 -> 74 ;
75 [label="entropy = 0.967\nsamples = 307\nvalue = [186, 121, 0]\nclass = Winner", fillcolor="#e5813959"] ;
74 -> 75 ;
76 [label="entropy = 0.0\nsamples = 5\nvalue = [0, 5, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
74 -> 76 ;
77 [label="X[45] <= 0.014\nentropy = 0.773\nsamples = 110\nvalue = [85, 25, 0]\nclass = Winner", fillcolor="#e58139b4"] ;
73 -> 77 ;
78 [label="entropy = 0.84\nsamples = 93\nvalue = [68, 25, 0]\nclass = Winner", fillcolor="#e58139a1"] ;
77 -> 78 ;
79 [label="entropy = 0.0\nsamples = 17\nvalue = [17, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
77 -> 79 ;
80 [label="X[38] <= 150.0\nentropy = 0.997\nsamples = 312\nvalue = [166, 146, 0]\nclass = Winner", fillcolor="#e581391f"] ;
48 -> 80 ;
81 [label="X[60] <= 0.687\nentropy = 0.965\nsamples = 100\nvalue = [39, 61, 0]\nclass = Loser", fillcolor="#39e5815c"] ;
80 -> 81 ;
82 [label="X[42] <= 0.359\nentropy = 0.99\nsamples = 50\nvalue = [28, 22, 0]\nclass = Winner", fillcolor="#e5813937"] ;
81 -> 82 ;
83 [label="X[42] <= 0.27\nentropy = 0.742\nsamples = 19\nvalue = [15, 4, 0]\nclass = Winner", fillcolor="#e58139bb"] ;
82 -> 83 ;
84 [label="entropy = 0.811\nsamples = 4\nvalue = [1, 3, 0]\nclass = Loser", fillcolor="#39e581aa"] ;
83 -> 84 ;
85 [label="entropy = 0.353\nsamples = 15\nvalue = [14, 1, 0]\nclass = Winner", fillcolor="#e58139ed"] ;
83 -> 85 ;
86 [label="X[39] <= 67.5\nentropy = 0.981\nsamples = 31\nvalue = [13, 18, 0]\nclass = Loser", fillcolor="#39e58147"] ;
82 -> 86 ;
87 [label="entropy = 0.863\nsamples = 14\nvalue = [10, 4, 0]\nclass = Winner", fillcolor="#e5813999"] ;
86 -> 87 ;
88 [label="entropy = 0.672\nsamples = 17\nvalue = [3, 14, 0]\nclass = Loser", fillcolor="#39e581c8"] ;
86 -> 88 ;
89 [label="X[59] <= 4.687\nentropy = 0.76\nsamples = 50\nvalue = [11, 39, 0]\nclass = Loser", fillcolor="#39e581b7"] ;
81 -> 89 ;
90 [label="X[59] <= 3.377\nentropy = 0.624\nsamples = 45\nvalue = [7, 38, 0]\nclass = Loser", fillcolor="#39e581d0"] ;
89 -> 90 ;
91 [label="entropy = 0.758\nsamples = 32\nvalue = [7, 25, 0]\nclass = Loser", fillcolor="#39e581b8"] ;
90 -> 91 ;
92 [label="entropy = 0.0\nsamples = 13\nvalue = [0, 13, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
90 -> 92 ;
93 [label="X[42] <= 0.398\nentropy = 0.722\nsamples = 5\nvalue = [4, 1, 0]\nclass = Winner", fillcolor="#e58139bf"] ;
89 -> 93 ;
94 [label="entropy = 0.0\nsamples = 4\nvalue = [4, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
93 -> 94 ;
95 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
93 -> 95 ;
96 [label="X[61] <= 0.013\nentropy = 0.971\nsamples = 212\nvalue = [127, 85, 0]\nclass = Winner", fillcolor="#e5813954"] ;
80 -> 96 ;
97 [label="X[42] <= 0.607\nentropy = 0.934\nsamples = 177\nvalue = [115, 62, 0]\nclass = Winner", fillcolor="#e5813976"] ;
96 -> 97 ;
98 [label="X[43] <= 3.961\nentropy = 0.955\nsamples = 165\nvalue = [103, 62, 0]\nclass = Winner", fillcolor="#e5813966"] ;
97 -> 98 ;
99 [label="entropy = 0.0\nsamples = 5\nvalue = [0, 5, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
98 -> 99 ;
100 [label="entropy = 0.94\nsamples = 160\nvalue = [103, 57, 0]\nclass = Winner", fillcolor="#e5813972"] ;
98 -> 100 ;
101 [label="entropy = 0.0\nsamples = 12\nvalue = [12, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
97 -> 101 ;
102 [label="X[57] <= 1.733\nentropy = 0.928\nsamples = 35\nvalue = [12, 23, 0]\nclass = Loser", fillcolor="#39e5817a"] ;
96 -> 102 ;
103 [label="X[41] <= 3.1\nentropy = 0.811\nsamples = 8\nvalue = [6, 2, 0]\nclass = Winner", fillcolor="#e58139aa"] ;
102 -> 103 ;
104 [label="entropy = 0.918\nsamples = 3\nvalue = [1, 2, 0]\nclass = Loser", fillcolor="#39e5817f"] ;
103 -> 104 ;
105 [label="entropy = 0.0\nsamples = 5\nvalue = [5, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
103 -> 105 ;
106 [label="X[42] <= 0.8\nentropy = 0.764\nsamples = 27\nvalue = [6, 21, 0]\nclass = Loser", fillcolor="#39e581b6"] ;
102 -> 106 ;
107 [label="entropy = 0.634\nsamples = 25\nvalue = [4, 21, 0]\nclass = Loser", fillcolor="#39e581ce"] ;
106 -> 107 ;
108 [label="entropy = 0.0\nsamples = 2\nvalue = [2, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
106 -> 108 ;
}

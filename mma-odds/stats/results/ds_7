digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label="X[43] <= 2.03\nentropy = 0.94\nsamples = 2855\nvalue = [1944, 897, 14]\nclass = Winner", fillcolor="#e5813988"] ;
1 [label="X[38] <= 162.5\nentropy = 0.835\nsamples = 1195\nvalue = [908, 280, 7]\nclass = Winner", fillcolor="#e58139af"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label="X[47] <= 0.099\nentropy = 0.971\nsamples = 475\nvalue = [323, 147, 5]\nclass = Winner", fillcolor="#e5813989"] ;
1 -> 2 ;
3 [label="X[55] <= 63.5\nentropy = 0.934\nsamples = 269\nvalue = [175, 94, 0]\nclass = Winner", fillcolor="#e5813976"] ;
2 -> 3 ;
4 [label="entropy = 0.0\nsamples = 15\nvalue = [15, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
3 -> 4 ;
5 [label="X[59] <= 4.258\nentropy = 0.951\nsamples = 254\nvalue = [160, 94, 0]\nclass = Winner", fillcolor="#e5813969"] ;
3 -> 5 ;
6 [label="X[50] <= 22.5\nentropy = 0.963\nsamples = 243\nvalue = [149, 94, 0]\nclass = Winner", fillcolor="#e581395e"] ;
5 -> 6 ;
7 [label="X[57] <= 3.367\nentropy = 0.983\nsamples = 210\nvalue = [121, 89, 0]\nclass = Winner", fillcolor="#e5813943"] ;
6 -> 7 ;
8 [label="entropy = 0.961\nsamples = 182\nvalue = [112, 70, 0]\nclass = Winner", fillcolor="#e5813960"] ;
7 -> 8 ;
9 [label="entropy = 0.906\nsamples = 28\nvalue = [9, 19, 0]\nclass = Loser", fillcolor="#39e58186"] ;
7 -> 9 ;
10 [label="X[35] <= 4.5\nentropy = 0.614\nsamples = 33\nvalue = [28, 5, 0]\nclass = Winner", fillcolor="#e58139d1"] ;
6 -> 10 ;
11 [label="entropy = 0.0\nsamples = 20\nvalue = [20, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
10 -> 11 ;
12 [label="entropy = 0.961\nsamples = 13\nvalue = [8, 5, 0]\nclass = Winner", fillcolor="#e5813960"] ;
10 -> 12 ;
13 [label="entropy = 0.0\nsamples = 11\nvalue = [11, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
5 -> 13 ;
14 [label="X[44] <= 0.744\nentropy = 0.977\nsamples = 206\nvalue = [148, 53, 5]\nclass = Winner", fillcolor="#e581399e"] ;
2 -> 14 ;
15 [label="X[27] <= 0.5\nentropy = 1.029\nsamples = 130\nvalue = [84, 44, 2]\nclass = Winner", fillcolor="#e5813977"] ;
14 -> 15 ;
16 [label="X[51] <= 4.5\nentropy = 0.959\nsamples = 103\nvalue = [74, 27, 2]\nclass = Winner", fillcolor="#e581399e"] ;
15 -> 16 ;
17 [label="X[9] <= 0.5\nentropy = 1.091\nsamples = 71\nvalue = [45, 24, 2]\nclass = Winner", fillcolor="#e5813972"] ;
16 -> 17 ;
18 [label="entropy = 1.026\nsamples = 58\nvalue = [41, 15, 2]\nclass = Winner", fillcolor="#e581399a"] ;
17 -> 18 ;
19 [label="entropy = 0.89\nsamples = 13\nvalue = [4, 9, 0]\nclass = Loser", fillcolor="#39e5818e"] ;
17 -> 19 ;
20 [label="X[57] <= 2.769\nentropy = 0.449\nsamples = 32\nvalue = [29, 3, 0]\nclass = Winner", fillcolor="#e58139e5"] ;
16 -> 20 ;
21 [label="entropy = 0.0\nsamples = 20\nvalue = [20, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
20 -> 21 ;
22 [label="entropy = 0.811\nsamples = 12\nvalue = [9, 3, 0]\nclass = Winner", fillcolor="#e58139aa"] ;
20 -> 22 ;
23 [label="X[61] <= 0.009\nentropy = 0.951\nsamples = 27\nvalue = [10, 17, 0]\nclass = Loser", fillcolor="#39e58169"] ;
15 -> 23 ;
24 [label="X[51] <= 3.5\nentropy = 0.722\nsamples = 20\nvalue = [4, 16, 0]\nclass = Loser", fillcolor="#39e581bf"] ;
23 -> 24 ;
25 [label="entropy = 0.0\nsamples = 11\nvalue = [0, 11, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
24 -> 25 ;
26 [label="entropy = 0.991\nsamples = 9\nvalue = [4, 5, 0]\nclass = Loser", fillcolor="#39e58133"] ;
24 -> 26 ;
27 [label="X[36] <= 0.5\nentropy = 0.592\nsamples = 7\nvalue = [6, 1, 0]\nclass = Winner", fillcolor="#e58139d4"] ;
23 -> 27 ;
28 [label="entropy = 0.0\nsamples = 6\nvalue = [6, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
27 -> 28 ;
29 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
27 -> 29 ;
30 [label="X[59] <= 1.514\nentropy = 0.757\nsamples = 76\nvalue = [64, 9, 3]\nclass = Winner", fillcolor="#e58139d1"] ;
14 -> 30 ;
31 [label="X[59] <= 1.265\nentropy = 1.173\nsamples = 27\nvalue = [18, 7, 2]\nclass = Winner", fillcolor="#e581398c"] ;
30 -> 31 ;
32 [label="X[47] <= 0.33\nentropy = 0.832\nsamples = 22\nvalue = [18, 3, 1]\nclass = Winner", fillcolor="#e58139c9"] ;
31 -> 32 ;
33 [label="entropy = 1.295\nsamples = 10\nvalue = [6, 3, 1]\nclass = Winner", fillcolor="#e581396d"] ;
32 -> 33 ;
34 [label="entropy = 0.0\nsamples = 12\nvalue = [12, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
32 -> 34 ;
35 [label="X[58] <= 0.51\nentropy = 0.722\nsamples = 5\nvalue = [0, 4, 1]\nclass = Loser", fillcolor="#39e581bf"] ;
31 -> 35 ;
36 [label="entropy = 0.0\nsamples = 4\nvalue = [0, 4, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
35 -> 36 ;
37 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]\nclass = N/A", fillcolor="#8139e5ff"] ;
35 -> 37 ;
38 [label="X[47] <= 0.107\nentropy = 0.389\nsamples = 49\nvalue = [46, 2, 1]\nclass = Winner", fillcolor="#e58139ef"] ;
30 -> 38 ;
39 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]\nclass = N/A", fillcolor="#8139e5ff"] ;
38 -> 39 ;
40 [label="X[50] <= 49.5\nentropy = 0.25\nsamples = 48\nvalue = [46, 2, 0]\nclass = Winner", fillcolor="#e58139f4"] ;
38 -> 40 ;
41 [label="entropy = 0.149\nsamples = 47\nvalue = [46, 1, 0]\nclass = Winner", fillcolor="#e58139f9"] ;
40 -> 41 ;
42 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
40 -> 42 ;
43 [label="X[51] <= 7.5\nentropy = 0.717\nsamples = 720\nvalue = [585, 133, 2]\nclass = Winner", fillcolor="#e58139c4"] ;
1 -> 43 ;
44 [label="X[46] <= 2.36\nentropy = 0.769\nsamples = 609\nvalue = [480, 127, 2]\nclass = Winner", fillcolor="#e58139bb"] ;
43 -> 44 ;
45 [label="X[58] <= 0.641\nentropy = 0.72\nsamples = 526\nvalue = [428, 96, 2]\nclass = Winner", fillcolor="#e58139c5"] ;
44 -> 45 ;
46 [label="X[39] <= 81.5\nentropy = 0.747\nsamples = 494\nvalue = [396, 96, 2]\nclass = Winner", fillcolor="#e58139c0"] ;
45 -> 46 ;
47 [label="X[45] <= 0.027\nentropy = 0.744\nsamples = 479\nvalue = [382, 96, 1]\nclass = Winner", fillcolor="#e58139be"] ;
46 -> 47 ;
48 [label="entropy = 0.735\nsamples = 460\nvalue = [365, 95, 0]\nclass = Winner", fillcolor="#e58139bd"] ;
47 -> 48 ;
49 [label="entropy = 0.591\nsamples = 19\nvalue = [17, 1, 1]\nclass = Winner", fillcolor="#e58139e3"] ;
47 -> 49 ;
50 [label="X[64] <= 0.011\nentropy = 0.353\nsamples = 15\nvalue = [14, 0, 1]\nclass = Winner", fillcolor="#e58139ed"] ;
46 -> 50 ;
51 [label="entropy = 0.0\nsamples = 14\nvalue = [14, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
50 -> 51 ;
52 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]\nclass = N/A", fillcolor="#8139e5ff"] ;
50 -> 52 ;
53 [label="entropy = 0.0\nsamples = 32\nvalue = [32, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
45 -> 53 ;
54 [label="X[50] <= 8.5\nentropy = 0.953\nsamples = 83\nvalue = [52, 31, 0]\nclass = Winner", fillcolor="#e5813967"] ;
44 -> 54 ;
55 [label="X[46] <= 3.562\nentropy = 0.684\nsamples = 11\nvalue = [2, 9, 0]\nclass = Loser", fillcolor="#39e581c6"] ;
54 -> 55 ;
56 [label="entropy = 0.0\nsamples = 8\nvalue = [0, 8, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
55 -> 56 ;
57 [label="X[63] <= 0.133\nentropy = 0.918\nsamples = 3\nvalue = [2, 1, 0]\nclass = Winner", fillcolor="#e581397f"] ;
55 -> 57 ;
58 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
57 -> 58 ;
59 [label="entropy = 0.0\nsamples = 2\nvalue = [2, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
57 -> 59 ;
60 [label="X[44] <= 0.689\nentropy = 0.888\nsamples = 72\nvalue = [50, 22, 0]\nclass = Winner", fillcolor="#e581398f"] ;
54 -> 60 ;
61 [label="X[46] <= 8.0\nentropy = 0.297\nsamples = 19\nvalue = [18, 1, 0]\nclass = Winner", fillcolor="#e58139f1"] ;
60 -> 61 ;
62 [label="entropy = 0.0\nsamples = 18\nvalue = [18, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
61 -> 62 ;
63 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
61 -> 63 ;
64 [label="X[43] <= 1.765\nentropy = 0.969\nsamples = 53\nvalue = [32, 21, 0]\nclass = Winner", fillcolor="#e5813958"] ;
60 -> 64 ;
65 [label="entropy = 1.0\nsamples = 39\nvalue = [20, 19, 0]\nclass = Winner", fillcolor="#e581390d"] ;
64 -> 65 ;
66 [label="entropy = 0.592\nsamples = 14\nvalue = [12, 2, 0]\nclass = Winner", fillcolor="#e58139d4"] ;
64 -> 66 ;
67 [label="X[62] <= 1.957\nentropy = 0.303\nsamples = 111\nvalue = [105, 6, 0]\nclass = Winner", fillcolor="#e58139f0"] ;
43 -> 67 ;
68 [label="entropy = 0.0\nsamples = 61\nvalue = [61, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
67 -> 68 ;
69 [label="X[47] <= 0.455\nentropy = 0.529\nsamples = 50\nvalue = [44, 6, 0]\nclass = Winner", fillcolor="#e58139dc"] ;
67 -> 69 ;
70 [label="X[39] <= 69.5\nentropy = 0.179\nsamples = 37\nvalue = [36, 1, 0]\nclass = Winner", fillcolor="#e58139f8"] ;
69 -> 70 ;
71 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
70 -> 71 ;
72 [label="entropy = 0.0\nsamples = 36\nvalue = [36, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
70 -> 72 ;
73 [label="X[48] <= 0.007\nentropy = 0.961\nsamples = 13\nvalue = [8, 5, 0]\nclass = Winner", fillcolor="#e5813960"] ;
69 -> 73 ;
74 [label="X[43] <= 1.527\nentropy = 0.954\nsamples = 8\nvalue = [3, 5, 0]\nclass = Loser", fillcolor="#39e58166"] ;
73 -> 74 ;
75 [label="entropy = 0.0\nsamples = 4\nvalue = [0, 4, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
74 -> 75 ;
76 [label="entropy = 0.811\nsamples = 4\nvalue = [3, 1, 0]\nclass = Winner", fillcolor="#e58139aa"] ;
74 -> 76 ;
77 [label="entropy = 0.0\nsamples = 5\nvalue = [5, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
73 -> 77 ;
78 [label="X[43] <= 3.944\nentropy = 0.988\nsamples = 1660\nvalue = [1036, 617, 7]\nclass = Winner", fillcolor="#e5813966"] ;
0 -> 78 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
79 [label="X[51] <= 2.5\nentropy = 0.977\nsamples = 1348\nvalue = [870, 471, 7]\nclass = Winner", fillcolor="#e5813974"] ;
78 -> 79 ;
80 [label="X[47] <= 0.163\nentropy = 1.044\nsamples = 512\nvalue = [290, 218, 4]\nclass = Winner", fillcolor="#e581393e"] ;
79 -> 80 ;
81 [label="X[60] <= 0.675\nentropy = 1.035\nsamples = 219\nvalue = [102, 116, 1]\nclass = Loser", fillcolor="#39e5811f"] ;
80 -> 81 ;
82 [label="X[43] <= 2.972\nentropy = 0.951\nsamples = 81\nvalue = [51, 30, 0]\nclass = Winner", fillcolor="#e5813969"] ;
81 -> 82 ;
83 [label="X[50] <= 10.5\nentropy = 0.803\nsamples = 49\nvalue = [37, 12, 0]\nclass = Winner", fillcolor="#e58139ac"] ;
82 -> 83 ;
84 [label="entropy = 0.937\nsamples = 34\nvalue = [22, 12, 0]\nclass = Winner", fillcolor="#e5813974"] ;
83 -> 84 ;
85 [label="entropy = 0.0\nsamples = 15\nvalue = [15, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
83 -> 85 ;
86 [label="X[64] <= 0.005\nentropy = 0.989\nsamples = 32\nvalue = [14, 18, 0]\nclass = Loser", fillcolor="#39e58139"] ;
82 -> 86 ;
87 [label="entropy = 0.918\nsamples = 27\nvalue = [9, 18, 0]\nclass = Loser", fillcolor="#39e5817f"] ;
86 -> 87 ;
88 [label="entropy = 0.0\nsamples = 5\nvalue = [5, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
86 -> 88 ;
89 [label="X[53] <= 74.5\nentropy = 1.007\nsamples = 138\nvalue = [51, 86, 1]\nclass = Loser", fillcolor="#39e58167"] ;
81 -> 89 ;
90 [label="X[45] <= 0.007\nentropy = 0.971\nsamples = 121\nvalue = [39, 81, 1]\nclass = Loser", fillcolor="#39e58183"] ;
89 -> 90 ;
91 [label="entropy = 0.706\nsamples = 52\nvalue = [10, 42, 0]\nclass = Loser", fillcolor="#39e581c2"] ;
90 -> 91 ;
92 [label="entropy = 1.079\nsamples = 69\nvalue = [29, 39, 1]\nclass = Loser", fillcolor="#39e58140"] ;
90 -> 92 ;
93 [label="X[37] <= 73.5\nentropy = 0.874\nsamples = 17\nvalue = [12, 5, 0]\nclass = Winner", fillcolor="#e5813995"] ;
89 -> 93 ;
94 [label="entropy = 0.991\nsamples = 9\nvalue = [4, 5, 0]\nclass = Loser", fillcolor="#39e58133"] ;
93 -> 94 ;
95 [label="entropy = 0.0\nsamples = 8\nvalue = [8, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
93 -> 95 ;
96 [label="X[63] <= 0.629\nentropy = 1.008\nsamples = 293\nvalue = [188, 102, 3]\nclass = Winner", fillcolor="#e5813973"] ;
80 -> 96 ;
97 [label="X[46] <= 1.971\nentropy = 0.95\nsamples = 241\nvalue = [166, 73, 2]\nclass = Winner", fillcolor="#e581398d"] ;
96 -> 97 ;
98 [label="X[43] <= 2.788\nentropy = 0.757\nsamples = 119\nvalue = [93, 26, 0]\nclass = Winner", fillcolor="#e58139b8"] ;
97 -> 98 ;
99 [label="entropy = 0.924\nsamples = 62\nvalue = [41, 21, 0]\nclass = Winner", fillcolor="#e581397c"] ;
98 -> 99 ;
100 [label="entropy = 0.429\nsamples = 57\nvalue = [52, 5, 0]\nclass = Winner", fillcolor="#e58139e6"] ;
98 -> 100 ;
101 [label="X[62] <= 3.125\nentropy = 1.071\nsamples = 122\nvalue = [73, 47, 2]\nclass = Winner", fillcolor="#e5813958"] ;
97 -> 101 ;
102 [label="entropy = 1.04\nsamples = 108\nvalue = [70, 36, 2]\nclass = Winner", fillcolor="#e5813978"] ;
101 -> 102 ;
103 [label="entropy = 0.75\nsamples = 14\nvalue = [3, 11, 0]\nclass = Loser", fillcolor="#39e581b9"] ;
101 -> 103 ;
104 [label="X[55] <= 72.5\nentropy = 1.104\nsamples = 52\nvalue = [22, 29, 1]\nclass = Loser", fillcolor="#39e5813c"] ;
96 -> 104 ;
105 [label="X[42] <= 0.405\nentropy = 0.906\nsamples = 28\nvalue = [19, 9, 0]\nclass = Winner", fillcolor="#e5813986"] ;
104 -> 105 ;
106 [label="entropy = 0.946\nsamples = 11\nvalue = [4, 7, 0]\nclass = Loser", fillcolor="#39e5816d"] ;
105 -> 106 ;
107 [label="entropy = 0.523\nsamples = 17\nvalue = [15, 2, 0]\nclass = Winner", fillcolor="#e58139dd"] ;
105 -> 107 ;
108 [label="X[47] <= 0.673\nentropy = 0.785\nsamples = 24\nvalue = [3, 20, 1]\nclass = Loser", fillcolor="#39e581ce"] ;
104 -> 108 ;
109 [label="entropy = 0.0\nsamples = 15\nvalue = [0, 15, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
108 -> 109 ;
110 [label="entropy = 1.352\nsamples = 9\nvalue = [3, 5, 1]\nclass = Loser", fillcolor="#39e58155"] ;
108 -> 110 ;
111 [label="X[57] <= 2.734\nentropy = 0.917\nsamples = 836\nvalue = [580, 253, 3]\nclass = Winner", fillcolor="#e581398f"] ;
79 -> 111 ;
112 [label="X[36] <= 0.5\nentropy = 0.864\nsamples = 414\nvalue = [309, 102, 3]\nclass = Winner", fillcolor="#e58139a9"] ;
111 -> 112 ;
113 [label="X[34] <= 30.0\nentropy = 0.763\nsamples = 325\nvalue = [257, 67, 1]\nclass = Winner", fillcolor="#e58139bc"] ;
112 -> 113 ;
114 [label="X[54] <= 255.0\nentropy = 0.731\nsamples = 316\nvalue = [255, 60, 1]\nclass = Winner", fillcolor="#e58139c2"] ;
113 -> 114 ;
115 [label="entropy = 0.681\nsamples = 305\nvalue = [250, 55, 0]\nclass = Winner", fillcolor="#e58139c7"] ;
114 -> 115 ;
116 [label="entropy = 1.349\nsamples = 11\nvalue = [5, 5, 1]\nclass = Winner", fillcolor="#e5813900"] ;
114 -> 116 ;
117 [label="X[12] <= 0.5\nentropy = 0.764\nsamples = 9\nvalue = [2, 7, 0]\nclass = Loser", fillcolor="#39e581b6"] ;
113 -> 117 ;
118 [label="entropy = 0.0\nsamples = 7\nvalue = [0, 7, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
117 -> 118 ;
119 [label="entropy = 0.0\nsamples = 2\nvalue = [2, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
117 -> 119 ;
120 [label="X[43] <= 2.192\nentropy = 1.106\nsamples = 89\nvalue = [52, 35, 2]\nclass = Winner", fillcolor="#e5813950"] ;
112 -> 120 ;
121 [label="X[48] <= 0.005\nentropy = 1.42\nsamples = 13\nvalue = [4, 7, 2]\nclass = Loser", fillcolor="#39e58155"] ;
120 -> 121 ;
122 [label="entropy = 0.811\nsamples = 8\nvalue = [0, 6, 2]\nclass = Loser", fillcolor="#39e581aa"] ;
121 -> 122 ;
123 [label="entropy = 0.722\nsamples = 5\nvalue = [4, 1, 0]\nclass = Winner", fillcolor="#e58139bf"] ;
121 -> 123 ;
124 [label="X[39] <= 76.5\nentropy = 0.949\nsamples = 76\nvalue = [48, 28, 0]\nclass = Winner", fillcolor="#e581396a"] ;
120 -> 124 ;
125 [label="entropy = 0.885\nsamples = 66\nvalue = [46, 20, 0]\nclass = Winner", fillcolor="#e5813990"] ;
124 -> 125 ;
126 [label="entropy = 0.722\nsamples = 10\nvalue = [2, 8, 0]\nclass = Loser", fillcolor="#39e581bf"] ;
124 -> 126 ;
127 [label="X[47] <= 0.38\nentropy = 0.941\nsamples = 422\nvalue = [271, 151, 0]\nclass = Winner", fillcolor="#e5813971"] ;
111 -> 127 ;
128 [label="X[47] <= 0.371\nentropy = 0.973\nsamples = 312\nvalue = [186, 126, 0]\nclass = Winner", fillcolor="#e5813952"] ;
127 -> 128 ;
129 [label="X[50] <= 6.5\nentropy = 0.967\nsamples = 307\nvalue = [186, 121, 0]\nclass = Winner", fillcolor="#e5813959"] ;
128 -> 129 ;
130 [label="entropy = 0.0\nsamples = 4\nvalue = [0, 4, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
129 -> 130 ;
131 [label="entropy = 0.962\nsamples = 303\nvalue = [186, 117, 0]\nclass = Winner", fillcolor="#e581395f"] ;
129 -> 131 ;
132 [label="entropy = 0.0\nsamples = 5\nvalue = [0, 5, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
128 -> 132 ;
133 [label="X[45] <= 0.014\nentropy = 0.773\nsamples = 110\nvalue = [85, 25, 0]\nclass = Winner", fillcolor="#e58139b4"] ;
127 -> 133 ;
134 [label="X[43] <= 2.207\nentropy = 0.84\nsamples = 93\nvalue = [68, 25, 0]\nclass = Winner", fillcolor="#e58139a1"] ;
133 -> 134 ;
135 [label="entropy = 0.764\nsamples = 9\nvalue = [2, 7, 0]\nclass = Loser", fillcolor="#39e581b6"] ;
134 -> 135 ;
136 [label="entropy = 0.75\nsamples = 84\nvalue = [66, 18, 0]\nclass = Winner", fillcolor="#e58139b9"] ;
134 -> 136 ;
137 [label="entropy = 0.0\nsamples = 17\nvalue = [17, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
133 -> 137 ;
138 [label="X[38] <= 150.0\nentropy = 0.997\nsamples = 312\nvalue = [166, 146, 0]\nclass = Winner", fillcolor="#e581391f"] ;
78 -> 138 ;
139 [label="X[60] <= 0.687\nentropy = 0.965\nsamples = 100\nvalue = [39, 61, 0]\nclass = Loser", fillcolor="#39e5815c"] ;
138 -> 139 ;
140 [label="X[42] <= 0.359\nentropy = 0.99\nsamples = 50\nvalue = [28, 22, 0]\nclass = Winner", fillcolor="#e5813937"] ;
139 -> 140 ;
141 [label="X[42] <= 0.27\nentropy = 0.742\nsamples = 19\nvalue = [15, 4, 0]\nclass = Winner", fillcolor="#e58139bb"] ;
140 -> 141 ;
142 [label="X[44] <= 0.651\nentropy = 0.811\nsamples = 4\nvalue = [1, 3, 0]\nclass = Loser", fillcolor="#39e581aa"] ;
141 -> 142 ;
143 [label="entropy = 0.0\nsamples = 1\nvalue = [1, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
142 -> 143 ;
144 [label="entropy = 0.0\nsamples = 3\nvalue = [0, 3, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
142 -> 144 ;
145 [label="X[17] <= 0.5\nentropy = 0.353\nsamples = 15\nvalue = [14, 1, 0]\nclass = Winner", fillcolor="#e58139ed"] ;
141 -> 145 ;
146 [label="entropy = 0.0\nsamples = 14\nvalue = [14, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
145 -> 146 ;
147 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
145 -> 147 ;
148 [label="X[39] <= 67.5\nentropy = 0.981\nsamples = 31\nvalue = [13, 18, 0]\nclass = Loser", fillcolor="#39e58147"] ;
140 -> 148 ;
149 [label="X[19] <= 0.5\nentropy = 0.863\nsamples = 14\nvalue = [10, 4, 0]\nclass = Winner", fillcolor="#e5813999"] ;
148 -> 149 ;
150 [label="entropy = 0.439\nsamples = 11\nvalue = [10, 1, 0]\nclass = Winner", fillcolor="#e58139e6"] ;
149 -> 150 ;
151 [label="entropy = 0.0\nsamples = 3\nvalue = [0, 3, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
149 -> 151 ;
152 [label="X[35] <= 1.5\nentropy = 0.672\nsamples = 17\nvalue = [3, 14, 0]\nclass = Loser", fillcolor="#39e581c8"] ;
148 -> 152 ;
153 [label="entropy = 0.985\nsamples = 7\nvalue = [3, 4, 0]\nclass = Loser", fillcolor="#39e58140"] ;
152 -> 153 ;
154 [label="entropy = 0.0\nsamples = 10\nvalue = [0, 10, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
152 -> 154 ;
155 [label="X[59] <= 4.687\nentropy = 0.76\nsamples = 50\nvalue = [11, 39, 0]\nclass = Loser", fillcolor="#39e581b7"] ;
139 -> 155 ;
156 [label="X[64] <= 0.002\nentropy = 0.624\nsamples = 45\nvalue = [7, 38, 0]\nclass = Loser", fillcolor="#39e581d0"] ;
155 -> 156 ;
157 [label="X[59] <= 3.386\nentropy = 0.758\nsamples = 32\nvalue = [7, 25, 0]\nclass = Loser", fillcolor="#39e581b8"] ;
156 -> 157 ;
158 [label="entropy = 0.902\nsamples = 22\nvalue = [7, 15, 0]\nclass = Loser", fillcolor="#39e58188"] ;
157 -> 158 ;
159 [label="entropy = 0.0\nsamples = 10\nvalue = [0, 10, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
157 -> 159 ;
160 [label="entropy = 0.0\nsamples = 13\nvalue = [0, 13, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
156 -> 160 ;
161 [label="X[52] <= 0.5\nentropy = 0.722\nsamples = 5\nvalue = [4, 1, 0]\nclass = Winner", fillcolor="#e58139bf"] ;
155 -> 161 ;
162 [label="entropy = 0.0\nsamples = 4\nvalue = [4, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
161 -> 162 ;
163 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
161 -> 163 ;
164 [label="X[61] <= 0.013\nentropy = 0.971\nsamples = 212\nvalue = [127, 85, 0]\nclass = Winner", fillcolor="#e5813954"] ;
138 -> 164 ;
165 [label="X[42] <= 0.607\nentropy = 0.934\nsamples = 177\nvalue = [115, 62, 0]\nclass = Winner", fillcolor="#e5813976"] ;
164 -> 165 ;
166 [label="X[43] <= 3.961\nentropy = 0.955\nsamples = 165\nvalue = [103, 62, 0]\nclass = Winner", fillcolor="#e5813966"] ;
165 -> 166 ;
167 [label="entropy = 0.0\nsamples = 5\nvalue = [0, 5, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
166 -> 167 ;
168 [label="X[60] <= 0.636\nentropy = 0.94\nsamples = 160\nvalue = [103, 57, 0]\nclass = Winner", fillcolor="#e5813972"] ;
166 -> 168 ;
169 [label="entropy = 0.998\nsamples = 59\nvalue = [28, 31, 0]\nclass = Loser", fillcolor="#39e58119"] ;
168 -> 169 ;
170 [label="entropy = 0.823\nsamples = 101\nvalue = [75, 26, 0]\nclass = Winner", fillcolor="#e58139a7"] ;
168 -> 170 ;
171 [label="entropy = 0.0\nsamples = 12\nvalue = [12, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
165 -> 171 ;
172 [label="X[57] <= 1.733\nentropy = 0.928\nsamples = 35\nvalue = [12, 23, 0]\nclass = Loser", fillcolor="#39e5817a"] ;
164 -> 172 ;
173 [label="X[41] <= 3.1\nentropy = 0.811\nsamples = 8\nvalue = [6, 2, 0]\nclass = Winner", fillcolor="#e58139aa"] ;
172 -> 173 ;
174 [label="X[44] <= 0.584\nentropy = 0.918\nsamples = 3\nvalue = [1, 2, 0]\nclass = Loser", fillcolor="#39e5817f"] ;
173 -> 174 ;
175 [label="entropy = 0.0\nsamples = 1\nvalue = [1, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
174 -> 175 ;
176 [label="entropy = 0.0\nsamples = 2\nvalue = [0, 2, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
174 -> 176 ;
177 [label="entropy = 0.0\nsamples = 5\nvalue = [5, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
173 -> 177 ;
178 [label="X[42] <= 0.8\nentropy = 0.764\nsamples = 27\nvalue = [6, 21, 0]\nclass = Loser", fillcolor="#39e581b6"] ;
172 -> 178 ;
179 [label="X[62] <= 1.721\nentropy = 0.634\nsamples = 25\nvalue = [4, 21, 0]\nclass = Loser", fillcolor="#39e581ce"] ;
178 -> 179 ;
180 [label="entropy = 0.918\nsamples = 12\nvalue = [4, 8, 0]\nclass = Loser", fillcolor="#39e5817f"] ;
179 -> 180 ;
181 [label="entropy = 0.0\nsamples = 13\nvalue = [0, 13, 0]\nclass = Loser", fillcolor="#39e581ff"] ;
179 -> 181 ;
182 [label="entropy = 0.0\nsamples = 2\nvalue = [2, 0, 0]\nclass = Winner", fillcolor="#e58139ff"] ;
178 -> 182 ;
}
